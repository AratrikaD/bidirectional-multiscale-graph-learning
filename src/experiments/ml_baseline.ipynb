{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_df = pd.read_csv(\"../../housing-data/all_neighborhood_features_rotterdam.csv\")\n",
    "transaction_df = pd.read_csv(\"../../housing-data/rotterdam_transaction_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUURTCODE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LEEFBAAROMETER</th>\n",
       "      <th>GROEN</th>\n",
       "      <th>EC</th>\n",
       "      <th>NO2</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>GELUIDSHINDERTOTAAL</th>\n",
       "      <th>AFSTANDTOTHUISARTSENPRAKTIJK</th>\n",
       "      <th>...</th>\n",
       "      <th>MOTORFIETSEN</th>\n",
       "      <th>AFSTANDTOTSCHOOL</th>\n",
       "      <th>SCHOLENBINNEN3KM</th>\n",
       "      <th>OPPERVLAKTETOTAAL</th>\n",
       "      <th>OPPERVLAKTELAND</th>\n",
       "      <th>OPPERVLAKTEWATER</th>\n",
       "      <th>MEESTVOORKOMENDEPOSTCODE</th>\n",
       "      <th>DEKKINGSPERCENTAGE</th>\n",
       "      <th>MATEVANSTEDELIJKHEID</th>\n",
       "      <th>OMGEVINGSADRESSENDICHTHEID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.085167</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>0.323869</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999997</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>9.099997</td>\n",
       "      <td>12.999996</td>\n",
       "      <td>12.999996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2990.999057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>2086.999342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.034464</td>\n",
       "      <td>0.041062</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.020684</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.016755</td>\n",
       "      <td>0.304635</td>\n",
       "      <td>0.293726</td>\n",
       "      <td>...</td>\n",
       "      <td>9.796313</td>\n",
       "      <td>0.293398</td>\n",
       "      <td>8.797291</td>\n",
       "      <td>17.599499</td>\n",
       "      <td>17.599499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2923.542404</td>\n",
       "      <td>0.977446</td>\n",
       "      <td>1.954893</td>\n",
       "      <td>1982.046788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.110514</td>\n",
       "      <td>0.031598</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.017139</td>\n",
       "      <td>0.322656</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.999992</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.199997</td>\n",
       "      <td>13.999996</td>\n",
       "      <td>13.999996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2991.999193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>1891.999490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.110993</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.022711</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.325598</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999997</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>11.199997</td>\n",
       "      <td>51.999987</td>\n",
       "      <td>51.999987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2990.999252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>1676.999580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.048586</td>\n",
       "      <td>0.038952</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.301614</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.999993</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9.099997</td>\n",
       "      <td>6.999998</td>\n",
       "      <td>6.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2990.999025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>1578.999485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6870</th>\n",
       "      <td>620</td>\n",
       "      <td>2024</td>\n",
       "      <td>4.042706</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>0.327098</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3238.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6871</th>\n",
       "      <td>621</td>\n",
       "      <td>2024</td>\n",
       "      <td>4.061659</td>\n",
       "      <td>0.047161</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.015409</td>\n",
       "      <td>0.321582</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3238.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6872</th>\n",
       "      <td>622</td>\n",
       "      <td>2024</td>\n",
       "      <td>4.269247</td>\n",
       "      <td>0.046067</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>0.330565</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3238.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>623</td>\n",
       "      <td>2024</td>\n",
       "      <td>4.166958</td>\n",
       "      <td>0.032288</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>0.315714</td>\n",
       "      <td>3.592785</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.195591</td>\n",
       "      <td>1.197595</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3238.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874</th>\n",
       "      <td>624</td>\n",
       "      <td>2024</td>\n",
       "      <td>4.110712</td>\n",
       "      <td>0.056326</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.345281</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3231.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6875 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BUURTCODE  YEAR  LEEFBAAROMETER     GROEN        EC       NO2     PM2_5  \\\n",
       "0             0  2014        4.085167  0.019481  0.000689  0.021756  0.010006   \n",
       "1             1  2014        4.034464  0.041062  0.000660  0.020684  0.009676   \n",
       "2             2  2014        4.110514  0.031598  0.000684  0.022700  0.009859   \n",
       "3             3  2014        4.110993  0.037557  0.000684  0.022711  0.009891   \n",
       "4             4  2014        4.048586  0.038952  0.000666  0.021961  0.009820   \n",
       "...         ...   ...             ...       ...       ...       ...       ...   \n",
       "6870        620  2024        4.042706  0.040761  0.000251  0.017493  0.007697   \n",
       "6871        621  2024        4.061659  0.047161  0.000250  0.017436  0.007677   \n",
       "6872        622  2024        4.269247  0.046067  0.000249  0.017399  0.007667   \n",
       "6873        623  2024        4.166958  0.032288  0.000240  0.017008  0.007543   \n",
       "6874        624  2024        4.110712  0.056326  0.000243  0.017815  0.007529   \n",
       "\n",
       "          PM10  GELUIDSHINDERTOTAAL  AFSTANDTOTHUISARTSENPRAKTIJK  ...  \\\n",
       "0     0.017313             0.323869                      0.400000  ...   \n",
       "1     0.016755             0.304635                      0.293726  ...   \n",
       "2     0.017139             0.322656                      0.200000  ...   \n",
       "3     0.017191             0.325598                      0.400000  ...   \n",
       "4     0.017036             0.301614                      0.500000  ...   \n",
       "...        ...                  ...                           ...  ...   \n",
       "6870  0.015455             0.327098                      3.400000  ...   \n",
       "6871  0.015409             0.321582                      3.600000  ...   \n",
       "6872  0.015397             0.330565                      3.800000  ...   \n",
       "6873  0.015186             0.315714                      3.592785  ...   \n",
       "6874  0.015110             0.345281                      4.900000  ...   \n",
       "\n",
       "      MOTORFIETSEN  AFSTANDTOTSCHOOL  SCHOLENBINNEN3KM  OPPERVLAKTETOTAAL  \\\n",
       "0         9.999997          0.800000          9.099997          12.999996   \n",
       "1         9.796313          0.293398          8.797291          17.599499   \n",
       "2        29.999992          0.300000         12.199997          13.999996   \n",
       "3         9.999997          0.700000         11.199997          51.999987   \n",
       "4        19.999993          0.900000          9.099997           6.999998   \n",
       "...            ...               ...               ...                ...   \n",
       "6870     30.000000          0.400000          1.500000          21.000000   \n",
       "6871     60.000000          0.800000          1.000000          30.000000   \n",
       "6872     10.000000          0.500000          1.000000          17.000000   \n",
       "6873     25.000000          2.195591          1.197595         884.000000   \n",
       "6874      0.000000          4.300000          0.000000         233.000000   \n",
       "\n",
       "      OPPERVLAKTELAND  OPPERVLAKTEWATER  MEESTVOORKOMENDEPOSTCODE  \\\n",
       "0           12.999996               0.0               2990.999057   \n",
       "1           17.599499               0.0               2923.542404   \n",
       "2           13.999996               0.0               2991.999193   \n",
       "3           51.999987               0.0               2990.999252   \n",
       "4            6.999998               0.0               2990.999025   \n",
       "...               ...               ...                       ...   \n",
       "6870        20.000000               0.0               3238.000000   \n",
       "6871        27.000000               4.0               3238.000000   \n",
       "6872        11.000000               6.0               3238.000000   \n",
       "6873       809.000000              75.0               3238.000000   \n",
       "6874       121.000000             112.0               3231.000000   \n",
       "\n",
       "      DEKKINGSPERCENTAGE  MATEVANSTEDELIJKHEID  OMGEVINGSADRESSENDICHTHEID  \n",
       "0               1.000000              1.999999                 2086.999342  \n",
       "1               0.977446              1.954893                 1982.046788  \n",
       "2               1.000000              1.999999                 1891.999490  \n",
       "3               1.000000              1.999999                 1676.999580  \n",
       "4               1.000000              1.999999                 1578.999485  \n",
       "...                  ...                   ...                         ...  \n",
       "6870            1.000000              5.000000                  281.000000  \n",
       "6871            3.000000              5.000000                  284.000000  \n",
       "6872            1.000000              5.000000                  278.000000  \n",
       "6873            1.000000              5.000000                   95.000000  \n",
       "6874            1.000000              5.000000                   84.000000  \n",
       "\n",
       "[6875 rows x 204 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df\n",
    "transaction_df['DATUM'] = pd.to_datetime(transaction_df['DATUM'])\n",
    "transaction_df.sort_values('DATUM', inplace=True)\n",
    "\n",
    "transaction_df['YEAR'] = transaction_df['DATUM'].dt.year\n",
    "transaction_df['MONTH'] = transaction_df['DATUM'].dt.month\n",
    "transaction_df.drop([ \"DATUM\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(transactions, node_features):\n",
    "    combined_df = transactions.merge(node_features,how=\"left\", on=[\"BUURTCODE\", \"YEAR\"])\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSID</th>\n",
       "      <th>WONINGTYPE</th>\n",
       "      <th>SOC</th>\n",
       "      <th>CALCOPP</th>\n",
       "      <th>KAVOPP</th>\n",
       "      <th>BOUWJAAR</th>\n",
       "      <th>BUURTCODE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>BESTEMMING</th>\n",
       "      <th>...</th>\n",
       "      <th>MOTORFIETSEN</th>\n",
       "      <th>AFSTANDTOTSCHOOL</th>\n",
       "      <th>SCHOLENBINNEN3KM</th>\n",
       "      <th>OPPERVLAKTETOTAAL</th>\n",
       "      <th>OPPERVLAKTELAND</th>\n",
       "      <th>OPPERVLAKTEWATER</th>\n",
       "      <th>MEESTVOORKOMENDEPOSTCODE</th>\n",
       "      <th>DEKKINGSPERCENTAGE</th>\n",
       "      <th>MATEVANSTEDELIJKHEID</th>\n",
       "      <th>OMGEVINGSADRESSENDICHTHEID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1182</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1945</td>\n",
       "      <td>371</td>\n",
       "      <td>51.914485</td>\n",
       "      <td>4.320525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.819022</td>\n",
       "      <td>0.283639</td>\n",
       "      <td>11.629200</td>\n",
       "      <td>66.182437</td>\n",
       "      <td>63.346047</td>\n",
       "      <td>2.836390</td>\n",
       "      <td>2961.191346</td>\n",
       "      <td>0.945463</td>\n",
       "      <td>1.890927</td>\n",
       "      <td>2190.638681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4329737</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1425</td>\n",
       "      <td>164</td>\n",
       "      <td>292</td>\n",
       "      <td>1984</td>\n",
       "      <td>457</td>\n",
       "      <td>52.006799</td>\n",
       "      <td>4.546388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.999978</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.999998</td>\n",
       "      <td>26.999991</td>\n",
       "      <td>26.999991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2664.999147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.999999</td>\n",
       "      <td>987.999684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4333802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1184</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1984</td>\n",
       "      <td>178</td>\n",
       "      <td>51.925000</td>\n",
       "      <td>4.476842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>352.517281</td>\n",
       "      <td>0.676276</td>\n",
       "      <td>44.044660</td>\n",
       "      <td>167.092214</td>\n",
       "      <td>130.386799</td>\n",
       "      <td>36.705415</td>\n",
       "      <td>2908.828268</td>\n",
       "      <td>0.966062</td>\n",
       "      <td>0.966062</td>\n",
       "      <td>6368.582264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4331781</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1131</td>\n",
       "      <td>130</td>\n",
       "      <td>149</td>\n",
       "      <td>1964</td>\n",
       "      <td>159</td>\n",
       "      <td>51.931712</td>\n",
       "      <td>4.232454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.999985</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.699999</td>\n",
       "      <td>81.999986</td>\n",
       "      <td>61.999990</td>\n",
       "      <td>19.999997</td>\n",
       "      <td>3144.999468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1789.999697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4344392</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1111</td>\n",
       "      <td>140</td>\n",
       "      <td>416</td>\n",
       "      <td>1991</td>\n",
       "      <td>523</td>\n",
       "      <td>51.831090</td>\n",
       "      <td>4.354248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108994</th>\n",
       "      <td>8849514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1188</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>192</td>\n",
       "      <td>51.902352</td>\n",
       "      <td>4.461150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>3024.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108995</th>\n",
       "      <td>8846853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1188</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1926</td>\n",
       "      <td>207</td>\n",
       "      <td>51.946392</td>\n",
       "      <td>4.463521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3051.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108996</th>\n",
       "      <td>8864162</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1131</td>\n",
       "      <td>126</td>\n",
       "      <td>130</td>\n",
       "      <td>1998</td>\n",
       "      <td>583</td>\n",
       "      <td>51.844048</td>\n",
       "      <td>4.161957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3223.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108997</th>\n",
       "      <td>8854064</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1136</td>\n",
       "      <td>213</td>\n",
       "      <td>104</td>\n",
       "      <td>1898</td>\n",
       "      <td>226</td>\n",
       "      <td>51.905242</td>\n",
       "      <td>4.510151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3071.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108998</th>\n",
       "      <td>8846884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1187</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1940</td>\n",
       "      <td>243</td>\n",
       "      <td>51.890887</td>\n",
       "      <td>4.477379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3083.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5088.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108999 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TRANSID  WONINGTYPE   SOC  CALCOPP  KAVOPP  BOUWJAAR  BUURTCODE  \\\n",
       "0       4329686         0.0  1182       90       0      1945        371   \n",
       "1       4329737         2.0  1425      164     292      1984        457   \n",
       "2       4333802         0.0  1184       90       0      1984        178   \n",
       "3       4331781         3.0  1131      130     149      1964        159   \n",
       "4       4344392         4.0  1111      140     416      1991        523   \n",
       "...         ...         ...   ...      ...     ...       ...        ...   \n",
       "108994  8849514         0.0  1188      131       0      2007        192   \n",
       "108995  8846853         0.0  1188       87       0      1926        207   \n",
       "108996  8864162         3.0  1131      126     130      1998        583   \n",
       "108997  8854064         3.0  1136      213     104      1898        226   \n",
       "108998  8846884         0.0  1187       51       0      1940        243   \n",
       "\n",
       "              LAT       LON  BESTEMMING  ...  MOTORFIETSEN  AFSTANDTOTSCHOOL  \\\n",
       "0       51.914485  4.320525         1.0  ...     89.819022          0.283639   \n",
       "1       52.006799  4.546388         1.0  ...     69.999978          0.400000   \n",
       "2       51.925000  4.476842         1.0  ...    352.517281          0.676276   \n",
       "3       51.931712  4.232454         1.0  ...     89.999985          0.500000   \n",
       "4       51.831090  4.354248         1.0  ...   -999.000000       -999.000000   \n",
       "...           ...       ...         ...  ...           ...               ...   \n",
       "108994  51.902352  4.461150         1.0  ...    105.000000          0.500000   \n",
       "108995  51.946392  4.463521         1.0  ...    230.000000          0.400000   \n",
       "108996  51.844048  4.161957         1.0  ...     75.000000          1.200000   \n",
       "108997  51.905242  4.510151         1.0  ...     55.000000          0.400000   \n",
       "108998  51.890887  4.477379         1.0  ...    220.000000          0.400000   \n",
       "\n",
       "        SCHOLENBINNEN3KM  OPPERVLAKTETOTAAL  OPPERVLAKTELAND  \\\n",
       "0              11.629200          66.182437        63.346047   \n",
       "1               4.999998          26.999991        26.999991   \n",
       "2              44.044660         167.092214       130.386799   \n",
       "3               8.699999          81.999986        61.999990   \n",
       "4            -999.000000        -999.000000      -999.000000   \n",
       "...                  ...                ...              ...   \n",
       "108994         20.600000         107.000000        47.000000   \n",
       "108995         28.600000         127.000000       119.000000   \n",
       "108996          5.300000          26.000000        22.000000   \n",
       "108997         23.800000         100.000000        63.000000   \n",
       "108998         34.800000          59.000000        59.000000   \n",
       "\n",
       "        OPPERVLAKTEWATER  MEESTVOORKOMENDEPOSTCODE  DEKKINGSPERCENTAGE  \\\n",
       "0               2.836390               2961.191346            0.945463   \n",
       "1               0.000000               2664.999147            1.000000   \n",
       "2              36.705415               2908.828268            0.966062   \n",
       "3              19.999997               3144.999468            1.000000   \n",
       "4            -999.000000               -999.000000         -999.000000   \n",
       "...                  ...                       ...                 ...   \n",
       "108994         61.000000               3024.000000            5.000000   \n",
       "108995          8.000000               3051.000000            1.000000   \n",
       "108996          3.000000               3223.000000            1.000000   \n",
       "108997         37.000000               3071.000000            1.000000   \n",
       "108998          0.000000               3083.000000            1.000000   \n",
       "\n",
       "        MATEVANSTEDELIJKHEID  OMGEVINGSADRESSENDICHTHEID  \n",
       "0                   1.890927                 2190.638681  \n",
       "1                   3.999999                  987.999684  \n",
       "2                   0.966062                 6368.582264  \n",
       "3                   2.000000                 1789.999697  \n",
       "4                -999.000000                 -999.000000  \n",
       "...                      ...                         ...  \n",
       "108994              1.000000                 3371.000000  \n",
       "108995              1.000000                 3168.000000  \n",
       "108996              3.000000                 1055.000000  \n",
       "108997              1.000000                 4005.000000  \n",
       "108998              1.000000                 5088.000000  \n",
       "\n",
       "[108999 rows x 219 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combine_data(transactions=transaction_df, node_features=neighborhood_df)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM with an 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X = combined_df.drop([\"LOG_KOOPSOM\"], axis=1)\n",
    "# y = combined_df[\"LOG_KOOPSOM\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# params = {'objective': 'L2', 'n_estimators': 1000, 'learning_rate': 0.05, \n",
    "#           'num_leaves': 1000, 'min_data_in_leaves': 10, 'feature_fraction': 0.7, 'max_depth': 75,\n",
    "#           'lambda_l2':10e-5, 'path_smooth': 10e-5, 'n_jobs': -1}\n",
    "# model = LGBMRegressor(**params, verbose=-1)\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# log_y_pred = model.predict(X_test, verbose=-1)\n",
    "# y_pred = np.exp(log_y_pred)\n",
    "# mape = np.abs(y_pred / np.exp(y_test) - 1).mean()\n",
    "# ratio =  np.mean(y_pred / np.exp(y_test))\n",
    "\n",
    "# print(f\"mean ratio: {ratio}, mape: {mape}\")\n",
    "\n",
    "# log_res = log_y_pred - y_test\n",
    "\n",
    "# bins = np.linspace(-0.75, 0.75, 51)\n",
    "# plt.hist(log_res, bins=bins, edgecolor='black')\n",
    "# plt.axvline(x=0, color='red', linestyle='--')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM with Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"DATE\"] = pd.to_datetime(combined_df[\"YEAR\"].astype(str) + \"-\" + combined_df[\"MONTH\"].astype(str))\n",
    "combined_df = combined_df.sort_values(\"DATE\")\n",
    "# combined_df = combined_df.drop(columns=[\"YEAR\", \"MONTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in combined_df.columns if col not in [\"LOG_KOOPSOM\", \"DATE\", \"TRANSID\"]]\n",
    "target = \"LOG_KOOPSOM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start Date:  2014-10-01 00:00:00\n",
      "Train End Date:  2019-10-01 00:00:00\n",
      "Test Month 2019-11-01 00:00:00\n",
      "918 test data points\n",
      "Training new model...\n",
      "current start: 2014-10-01 00:00:00\n",
      "updated start 2014-11-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-11-01 00:00:00\n",
      "Updated Train End Date:  2019-11-01 00:00:00\n",
      "Updated Test Month:  2019-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Train Start Date:  2014-11-01 00:00:00\n",
      "Train End Date:  2019-11-01 00:00:00\n",
      "Test Month 2019-12-01 00:00:00\n",
      "1178 test data points\n",
      "Updating model with new data...\n",
      "current start: 2014-10-01 00:00:00\n",
      "updated start 2014-11-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-11-01 00:00:00\n",
      "Updated Train End Date:  2019-11-01 00:00:00\n",
      "Updated Test Month:  2019-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Train Start Date:  2014-11-01 00:00:00\n",
      "Train End Date:  2019-11-01 00:00:00\n",
      "Test Month 2019-12-01 00:00:00\n",
      "1178 test data points\n",
      "Updating model with new data...\n",
      "current start: 2014-11-01 00:00:00\n",
      "updated start 2014-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-12-01 00:00:00\n",
      "Updated Train End Date:  2019-12-01 00:00:00\n",
      "Updated Test Month:  2020-01-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Train Start Date:  2014-12-01 00:00:00\n",
      "Train End Date:  2019-12-01 00:00:00\n",
      "Test Month 2020-01-01 00:00:00\n",
      "871 test data points\n",
      "Updating model with new data...\n",
      "current start: 2014-11-01 00:00:00\n",
      "updated start 2014-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-12-01 00:00:00\n",
      "Updated Train End Date:  2019-12-01 00:00:00\n",
      "Updated Test Month:  2020-01-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Train Start Date:  2014-12-01 00:00:00\n",
      "Train End Date:  2019-12-01 00:00:00\n",
      "Test Month 2020-01-01 00:00:00\n",
      "871 test data points\n",
      "Updating model with new data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m     new_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbase_params, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m}\n\u001b[0;32m     51\u001b[0m     model \u001b[38;5;241m=\u001b[39m LGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_params, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_booster\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Booster, not the wrapper\u001b[39;49;00m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     prev_booster \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbooster_ \n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent start:\u001b[39m\u001b[38;5;124m\"\u001b[39m, start_train)\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    311\u001b[0m     cb(\n\u001b[0;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m         )\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4154\u001b[0m _safe_call(\n\u001b[1;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4159\u001b[0m )\n\u001b[0;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "min_date = combined_df[\"DATE\"].min()\n",
    "max_date = combined_df[\"DATE\"].max()\n",
    "\n",
    "start_train = min_date\n",
    "end_train = start_train + pd.DateOffset(months=60)\n",
    "test_month = end_train + pd.DateOffset(months=1)\n",
    "\n",
    "model = None\n",
    "scaler = StandardScaler()\n",
    "all_window_preds = []\n",
    "\n",
    "# To track relative errors per epoch\n",
    "epoch_stats = []\n",
    "prev_booster = None \n",
    "\n",
    "while test_month <= max_date:\n",
    "    print(\"Train Start Date: \",start_train )\n",
    "    print(\"Train End Date: \", end_train )\n",
    "    print(\"Test Month\", test_month)\n",
    "\n",
    "    train_data = combined_df[(combined_df[\"DATE\"] >= start_train) & (combined_df[\"DATE\"] <= end_train)]\n",
    "    test_data = combined_df[combined_df[\"DATE\"] == test_month]\n",
    "    print(len(test_data), \"test data points\")\n",
    "    if test_data.empty:\n",
    "        print(\"empty\")\n",
    "        break\n",
    "\n",
    "\n",
    "    base_params = {'objective': 'L2', 'n_estimators': 50, 'learning_rate': 0.05, \n",
    "          'num_leaves': 1000, 'min_data_in_leaves': 10, 'feature_fraction': 0.7, 'max_depth': 75,\n",
    "          'lambda_l2':10e-5, 'path_smooth': 10e-5, 'n_jobs': -1}\n",
    "    \n",
    "    # if model==None:\n",
    "    #     scaler.fit(X_train)  # Fit scaler only on first window\n",
    "    # else:\n",
    "    #     scaler.partial_fit(X_train)  # Update scaler with new window\n",
    "\n",
    "    # X_train_scaled = scaler.transform(X_train)\n",
    "    # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    if model is None:\n",
    "        print(\"Training new model...\")\n",
    "        model = LGBMRegressor(**base_params, verbose=-1)\n",
    "        model.fit(train_data[features], train_data[target])\n",
    "    else:\n",
    "        print(\"Updating model with new data...\", flush=True)\n",
    "        \n",
    "        new_params = {**base_params, \"n_estimators\": 50}\n",
    "        model = LGBMRegressor(**new_params, verbose=-1)\n",
    "        model.fit(\n",
    "            train_data[features],\n",
    "            train_data[target],\n",
    "            init_model=prev_booster           # Booster, not the wrapper\n",
    "        )\n",
    "        prev_booster = model.booster_ \n",
    "    print(\"current start:\", start_train)\n",
    "    start_train += pd.DateOffset(months=1)\n",
    "    print(\"updated start\", start_train)\n",
    "    end_train += pd.DateOffset(months=1)\n",
    "    test_month += pd.DateOffset(months=1)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Updated Train Start Date: \", start_train)\n",
    "    print(\"Updated Train End Date: \", end_train)\n",
    "    print(\"Updated Test Month: \", test_month)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "neighborhood_df = pd.read_csv(\"../../housing-data/all_neighborhood_features_rotterdam.csv\")\n",
    "transaction_df = pd.read_csv(\"../../housing-data/rotterdam_transaction_data.csv\")\n",
    "\n",
    "# Preprocess transaction data\n",
    "transaction_df['DATUM'] = pd.to_datetime(transaction_df['DATUM'])\n",
    "transaction_df.sort_values('DATUM', inplace=True)\n",
    "transaction_df['YEAR'] = transaction_df['DATUM'].dt.year\n",
    "transaction_df['MONTH'] = transaction_df['DATUM'].dt.month\n",
    "transaction_df.drop([\"DATUM\"], axis=1, inplace=True)\n",
    "\n",
    "# Combine data\n",
    "def combine_data(transactions, node_features):\n",
    "    combined_df = transactions.merge(node_features, how=\"left\", on=[\"BUURTCODE\", \"YEAR\"])\n",
    "    return combined_df\n",
    "\n",
    "combined_df = combine_data(transactions=transaction_df, node_features=neighborhood_df)\n",
    "\n",
    "# Add DATE column and sort\n",
    "combined_df[\"DATE\"] = pd.to_datetime(combined_df[\"YEAR\"].astype(str) + \"-\" + combined_df[\"MONTH\"].astype(str))\n",
    "combined_df = combined_df.sort_values(\"DATE\")\n",
    "\n",
    "# Feature selection\n",
    "features = [col for col in combined_df.columns if col not in [\"LOG_KOOPSOM\", \"DATE\", \"TRANSID\"]]\n",
    "target = \"LOG_KOOPSOM\"\n",
    "\n",
    "# LightGBM with Sliding Windows\n",
    "min_date = combined_df[\"DATE\"].min()\n",
    "max_date = combined_df[\"DATE\"].max()\n",
    "start_train = min_date\n",
    "end_train = start_train + pd.DateOffset(months=60)\n",
    "test_month = end_train + pd.DateOffset(months=1)\n",
    "\n",
    "model = None\n",
    "scaler = StandardScaler()\n",
    "all_window_preds = []\n",
    "epoch_stats = []\n",
    "prev_booster = None\n",
    "\n",
    "while test_month <= max_date:\n",
    "    print(\"Train Start Date: \", start_train)\n",
    "    print(\"Train End Date: \", end_train)\n",
    "    print(\"Test Month\", test_month)\n",
    "\n",
    "    train_data = combined_df[(combined_df[\"DATE\"] >= start_train) & (combined_df[\"DATE\"] <= end_train)]\n",
    "    test_data = combined_df[combined_df[\"DATE\"] == test_month]\n",
    "    print(len(test_data), \"test data points\")\n",
    "    if test_data.empty:\n",
    "        print(\"empty\")\n",
    "        break\n",
    "\n",
    "    base_params = {'objective': 'L2', 'n_estimators': 50, 'learning_rate': 0.05,\n",
    "                   'num_leaves': 1000, 'min_data_in_leaves': 10, 'feature_fraction': 0.7, 'max_depth': 75,\n",
    "                   'lambda_l2': 10e-5, 'path_smooth': 10e-5, 'n_jobs': -1}\n",
    "\n",
    "    if model is None:\n",
    "        print(\"Training new model...\")\n",
    "        model = LGBMRegressor(**base_params, verbose=-1)\n",
    "        model.fit(train_data[features], train_data[target])\n",
    "        prev_booster = model.booster_\n",
    "    else:\n",
    "        print(\"Updating model with new data...\", flush=True)\n",
    "        new_params = {**base_params, \"n_estimators\": 50}\n",
    "        model = LGBMRegressor(**new_params, verbose=-1)\n",
    "        model.fit(\n",
    "            train_data[features],\n",
    "            train_data[target],\n",
    "            init_model=prev_booster\n",
    "        )\n",
    "        prev_booster = model.booster_\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(test_data[features])\n",
    "    actuals = test_data[target].values\n",
    "\n",
    "    # Train predictions for metrics\n",
    "    train_preds = model.predict(train_data[features])\n",
    "    train_mse = np.mean((train_data[target] - train_preds) ** 2)\n",
    "    train_mape = np.mean(np.abs((np.exp(train_data[target]) - np.exp(train_preds)) / np.exp(train_data[target]))) * 100\n",
    "\n",
    "    print(f\"Train MSE: {train_mse}\")\n",
    "    print(f\"Train MAPE: {train_mape}\")\n",
    "\n",
    "    mse = np.mean((actuals - predictions) ** 2)\n",
    "    print(f\"MSE: {mse}\")\n",
    "    mape = np.mean(np.abs((np.exp(actuals) - np.exp(predictions)) / np.exp(predictions))) * 100\n",
    "    print(f\"MAPE: {mape}\")\n",
    "\n",
    "    epoch_stats.append({\n",
    "        \"window_start\": start_train.strftime('%Y-%m'),\n",
    "        \"epoch\": 1,\n",
    "        \"train_mape\": train_mape,\n",
    "        \"test_mape\": mape,\n",
    "        \"train_mse\": train_mse,\n",
    "        \"test_mse\": mse,\n",
    "    })\n",
    "    preds_df = pd.DataFrame({\n",
    "        \"window_start\": start_train.strftime('%Y-%m'),\n",
    "        \"BUURTCODE\": test_data[\"BUURTCODE\"].values,\n",
    "        \"YEAR\": test_data[\"YEAR\"].values,\n",
    "        \"MONTH\": test_data[\"MONTH\"].values,\n",
    "        \"TRANSID\": test_data[\"TRANSID\"].values,\n",
    "        \"y_true\": actuals,\n",
    "        \"y_pred\": predictions,\n",
    "    })\n",
    "\n",
    "    all_window_preds.append(preds_df)\n",
    "    # Move window forward\n",
    "    print(\"current start:\", start_train)\n",
    "    start_train += pd.DateOffset(months=1)\n",
    "    print(\"updated start\", start_train)\n",
    "    end_train += pd.DateOffset(months=1)\n",
    "    test_month += pd.DateOffset(months=1)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Updated Train Start Date: \", start_train)\n",
    "    print(\"Updated Train End Date: \", end_train)\n",
    "    print(\"Updated Test Month: \", test_month)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "# Save predictions and stats\n",
    "final_preds_df = pd.concat(all_window_preds, ignore_index=True)\n",
    "final_preds_df.to_csv(\"./outputs/all_test_predictions_ml.csv\", index=False)\n",
    "\n",
    "stats_df = pd.DataFrame(epoch_stats)\n",
    "stats_df.to_csv(\"./outputs/training_stats_ml.csv\", index=False)\n",
    "\n",
    "# Online Learning Approach (example, not run above)\n",
    "# df = combined_df\n",
    "# scaler = RobustScaler()\n",
    "# params = {'objective': 'L2', 'n_estimators': 1000, 'learning_rate': 0.05,\n",
    "#           'num_leaves': 1000, 'min_data_in_leaves': 10, 'feature_fraction': 0.7, 'max_depth': 75,\n",
    "#           'lambda_l2': 10e-5, 'path_smooth': 10e-5, 'n_jobs': -1}\n",
    "# model = LGBMRegressor(**params, verbose=-1)\n",
    "# min_date = df[\"DATE\"].min()\n",
    "# max_date = df[\"DATE\"].max()\n",
    "# start_train = min_date\n",
    "# test_month = start_train + pd.DateOffset(months=60)\n",
    "# predictions = []\n",
    "# actuals = []\n",
    "# while test_month <= max_date:\n",
    "#     train_idx = df[\"DATE\"] < test_month\n",
    "#     test_idx = df[\"DATE\"] == test_month\n",
    "#     print(\"Test Month:\", test_month)\n",
    "#     X_train, y_train = df.loc[train_idx, features], df.loc[train_idx, target]\n",
    "#     X_test, y_test = df.loc[test_idx, features], df.loc[test_idx, target]\n",
    "#     if X_train.empty or X_test.empty:\n",
    "#         break\n",
    "#     if start_train == min_date:\n",
    "#         model.fit(X_train, y_train)\n",
    "#     else:\n",
    "#         model.set_params(n_estimators=model.n_estimators + 20)\n",
    "#         model.fit(X_train, y_train, init_model=model)\n",
    "#     preds = model.predict(X_test)\n",
    "#     predictions.extend(preds)\n",
    "#     actuals.extend(y_test.values)\n",
    "#     rmse = root_mean_squared_error(actuals, predictions)\n",
    "#     print(f\"RMSE: {rmse}\")\n",
    "#     mape = np.mean(np.abs((np.exp(actuals) - np.exp(predictions)) / np.exp(predictions))) * 100\n",
    "#     print(f\"MAPE: {mape}\")\n",
    "#     test_month += pd.DateOffset(months=1)\n",
    "# rmse = root_mean_squared_error(actuals, predictions)\n",
    "# print(f\"Final RMSE: {rmse}\")\n",
    "# mape = np.mean(np.abs((np.exp(actuals) - np.exp(predictions)) / np.exp(predictions))) * 100\n",
    "# print(f\"Final MAPE: {mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 New loop iteration - start_train: 2014-10-01 00:00:00\n",
      "Train Start Date:  2014-10-01 00:00:00\n",
      "Train End Date:  2019-10-01 00:00:00\n",
      "Test Month 2019-11-01 00:00:00\n",
      "918 test data points\n",
      "Train MSE: 0.012669311992354595\n",
      "Train MAPE: 8.490367452729698\n",
      "MSE: 0.01660803436109644\n",
      "MAPE: 10.20702473330138\n",
      "current start: 2014-10-01 00:00:00\n",
      "updated start 2014-11-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-11-01 00:00:00\n",
      "Updated Train End Date:  2019-11-01 00:00:00\n",
      "Updated Test Month:  2019-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "🔁 New loop iteration - start_train: 2014-11-01 00:00:00\n",
      "Train Start Date:  2014-11-01 00:00:00\n",
      "Train End Date:  2019-11-01 00:00:00\n",
      "Test Month 2019-12-01 00:00:00\n",
      "1178 test data points\n",
      "Train MSE: 0.012669311992354595\n",
      "Train MAPE: 8.490367452729698\n",
      "MSE: 0.01660803436109644\n",
      "MAPE: 10.20702473330138\n",
      "current start: 2014-10-01 00:00:00\n",
      "updated start 2014-11-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-11-01 00:00:00\n",
      "Updated Train End Date:  2019-11-01 00:00:00\n",
      "Updated Test Month:  2019-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "🔁 New loop iteration - start_train: 2014-11-01 00:00:00\n",
      "Train Start Date:  2014-11-01 00:00:00\n",
      "Train End Date:  2019-11-01 00:00:00\n",
      "Test Month 2019-12-01 00:00:00\n",
      "1178 test data points\n",
      "Train MSE: 0.006194657263856961\n",
      "Train MAPE: 5.844518733874662\n",
      "MSE: 0.015259478320540558\n",
      "MAPE: 9.092997002209124\n",
      "current start: 2014-11-01 00:00:00\n",
      "updated start 2014-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-12-01 00:00:00\n",
      "Updated Train End Date:  2019-12-01 00:00:00\n",
      "Updated Test Month:  2020-01-01 00:00:00\n",
      "--------------------------------------------------\n",
      "🔁 New loop iteration - start_train: 2014-12-01 00:00:00\n",
      "Train Start Date:  2014-12-01 00:00:00\n",
      "Train End Date:  2019-12-01 00:00:00\n",
      "Test Month 2020-01-01 00:00:00\n",
      "871 test data points\n",
      "Train MSE: 0.006194657263856961\n",
      "Train MAPE: 5.844518733874662\n",
      "MSE: 0.015259478320540558\n",
      "MAPE: 9.092997002209124\n",
      "current start: 2014-11-01 00:00:00\n",
      "updated start 2014-12-01 00:00:00\n",
      "--------------------------------------------------\n",
      "Updated Train Start Date:  2014-12-01 00:00:00\n",
      "Updated Train End Date:  2019-12-01 00:00:00\n",
      "Updated Test Month:  2020-01-01 00:00:00\n",
      "--------------------------------------------------\n",
      "🔁 New loop iteration - start_train: 2014-12-01 00:00:00\n",
      "Train Start Date:  2014-12-01 00:00:00\n",
      "Train End Date:  2019-12-01 00:00:00\n",
      "Test Month 2020-01-01 00:00:00\n",
      "871 test data points\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_params(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     59\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data[features])\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    311\u001b[0m     cb(\n\u001b[0;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m         )\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AratrikaD\\rdlabs-gnns-for-property-valuation\\.venv\\lib\\site-packages\\lightgbm\\basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4154\u001b[0m _safe_call(\n\u001b[1;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4159\u001b[0m )\n\u001b[0;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "\n",
    "min_date = combined_df[\"DATE\"].min()\n",
    "max_date = combined_df[\"DATE\"].max()\n",
    "\n",
    "start_train = min_date\n",
    "end_train = start_train + pd.DateOffset(months=60)\n",
    "test_month = end_train + pd.DateOffset(months=1)\n",
    "model = None\n",
    "scaler = StandardScaler()\n",
    "all_window_preds = []\n",
    "\n",
    "# To track relative errors per epoch\n",
    "epoch_stats = []\n",
    "\n",
    "\n",
    "while test_month <= max_date:\n",
    "    print(\"🔁 New loop iteration - start_train:\", start_train)\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    print(\"Train Start Date: \",start_train )\n",
    "    print(\"Train End Date: \", end_train )\n",
    "    print(\"Test Month\", test_month)\n",
    "    # Train/Test Split\n",
    "    train_data = combined_df[(combined_df[\"DATE\"] >= start_train) & (combined_df[\"DATE\"] <= end_train)]\n",
    "    test_data = combined_df[combined_df[\"DATE\"] == test_month]\n",
    "    print(len(test_data), \"test data points\")\n",
    "    if test_data.empty:\n",
    "        print(\"empty\")\n",
    "        break\n",
    "\n",
    "    # LightGBM dataset\n",
    "    # train_set = lgb.Dataset(train_data[features], label=train_data[target])\n",
    "    # test_set = lgb.Dataset(test_data[features], label=test_data[target], reference=train_set)\n",
    "\n",
    "    # Train model\n",
    " \n",
    "    params = {'objective': 'L2', 'n_estimators': 50, 'learning_rate': 0.05, \n",
    "          'num_leaves': 1000, 'min_data_in_leaves': 10, 'feature_fraction': 0.7, 'max_depth': 75,\n",
    "          'lambda_l2':10e-5, 'path_smooth': 10e-5, 'n_jobs': -1}\n",
    "    \n",
    "    # if model==None:\n",
    "    #     scaler.fit(X_train)  # Fit scaler only on first window\n",
    "    # else:\n",
    "    #     scaler.partial_fit(X_train)  # Update scaler with new window\n",
    "\n",
    "    # X_train_scaled = scaler.transform(X_train)\n",
    "    # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    if model is None:\n",
    "        model = LGBMRegressor(**params, verbose=-1)\n",
    "        model.fit(train_data[features], train_data[target])\n",
    "    else:\n",
    "        model.set_params(n_estimators=50)\n",
    "        model.fit(train_data[features], train_data[target], init_model=model)\n",
    "\n",
    "    # Make predictions\n",
    "    preds = model.predict(test_data[features])\n",
    "\n",
    "    # Store results\n",
    "    predictions = preds\n",
    "    actuals= test_data[target].values\n",
    "\n",
    "\n",
    "    # Train predictions for metrics\n",
    "    train_preds = model.predict(train_data[features])\n",
    "    train_mse = np.mean((train_data[target] - train_preds) ** 2)\n",
    "    train_mape = np.mean(np.abs((np.exp(train_data[target]) - np.exp(train_preds)) / np.exp(train_data[target]))) * 100\n",
    "\n",
    "    print(f\"Train MSE: {train_mse}\")\n",
    "    print(f\"Train MAPE: {train_mape}\")\n",
    "\n",
    "\n",
    "    mse = np.mean((actuals - predictions) ** 2)\n",
    "    print(f\"MSE: {mse}\")\n",
    "    mape = np.mean(np.abs((np.exp(actuals) - np.exp(predictions)) / np.exp(predictions))) * 100\n",
    "    print(f\"MAPE: {mape}\")\n",
    "\n",
    "    epoch_stats.append({\n",
    "        \"window_start\": start_train.strftime('%Y-%m'),\n",
    "        \"epoch\":  1,\n",
    "        \"train_mape\": train_mape,\n",
    "        \"test_mape\": mape,\n",
    "        \"train_mse\": train_mse,\n",
    "        \"test_mse\": mse,\n",
    "    })\n",
    "    preds_df = pd.DataFrame({\n",
    "        \"window_start\": start_train.strftime('%Y-%m'),\n",
    "        \"BUURTCODE\": test_data[\"BUURTCODE\"].values,\n",
    "        \"YEAR\": test_data[\"YEAR\"].values,\n",
    "        \"MONTH\": test_data[\"MONTH\"].values,\n",
    "        \"TRANSID\": test_data[\"TRANSID\"].values,\n",
    "        \"y_true\": actuals,\n",
    "        \"y_pred\": predictions,\n",
    "    })\n",
    "\n",
    "    all_window_preds.append(preds_df)\n",
    "    # Move window forward\n",
    "    print(\"current start:\", start_train)\n",
    "    start_train += pd.DateOffset(months=1)\n",
    "    print(\"updated start\", start_train)\n",
    "    end_train += pd.DateOffset(months=1)\n",
    "    test_month += pd.DateOffset(months=1)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Updated Train Start Date: \", start_train)\n",
    "    print(\"Updated Train End Date: \", end_train)\n",
    "    print(\"Updated Test Month: \", test_month)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds_df = pd.concat(all_window_preds, ignore_index=True)\n",
    "final_preds_df.to_csv(\"./outputs/all_test_predictions_ml.csv\", index=False)\n",
    "\n",
    "# Save epoch stats\n",
    "stats_df = pd.DataFrame(epoch_stats)\n",
    "stats_df.to_csv(\"./outputs/training_stats_ml.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Month: 2019-10-01 00:00:00\n",
      "RMSE: 0.1477269928581607\n",
      "MAPE: 11.297929704263776\n",
      "Test Month: 2019-11-01 00:00:00\n",
      "RMSE: 0.1376991619843752\n",
      "MAPE: 10.487919022062417\n",
      "Test Month: 2019-12-01 00:00:00\n",
      "RMSE: 0.13644349109291237\n",
      "MAPE: 10.453727734098088\n",
      "Test Month: 2020-01-01 00:00:00\n",
      "RMSE: 0.13571400975141956\n",
      "MAPE: 10.412903234560158\n",
      "Test Month: 2020-02-01 00:00:00\n",
      "RMSE: 0.13484406451349926\n",
      "MAPE: 10.29009970190649\n",
      "Test Month: 2020-03-01 00:00:00\n",
      "RMSE: 0.13322527662717226\n",
      "MAPE: 10.177226541421131\n",
      "Test Month: 2020-04-01 00:00:00\n",
      "RMSE: 0.13230793836131105\n",
      "MAPE: 10.14182133546273\n",
      "Test Month: 2020-05-01 00:00:00\n",
      "RMSE: 0.13155308815695144\n",
      "MAPE: 10.059542687602722\n",
      "Test Month: 2020-06-01 00:00:00\n",
      "RMSE: 0.13063058719143186\n",
      "MAPE: 9.99038633711236\n",
      "Test Month: 2020-07-01 00:00:00\n",
      "RMSE: 0.13018470926450842\n",
      "MAPE: 9.94484297618403\n",
      "Test Month: 2020-08-01 00:00:00\n",
      "RMSE: 0.12957488803178663\n",
      "MAPE: 9.922042973513186\n",
      "Test Month: 2020-09-01 00:00:00\n",
      "RMSE: 0.12934474435491058\n",
      "MAPE: 9.913381616781065\n",
      "Test Month: 2020-10-01 00:00:00\n",
      "RMSE: 0.12901825272011347\n",
      "MAPE: 9.919835592247386\n",
      "Test Month: 2020-11-01 00:00:00\n",
      "RMSE: 0.12902616486152185\n",
      "MAPE: 9.915899366898516\n",
      "Test Month: 2020-12-01 00:00:00\n",
      "RMSE: 0.13154796297580126\n",
      "MAPE: 10.083453716930668\n",
      "Test Month: 2021-01-01 00:00:00\n",
      "RMSE: 0.13136248493946623\n",
      "MAPE: 10.125871046320198\n",
      "Test Month: 2021-02-01 00:00:00\n",
      "RMSE: 0.13075127676233456\n",
      "MAPE: 10.081859132066743\n",
      "Test Month: 2021-03-01 00:00:00\n",
      "RMSE: 0.13064005772081075\n",
      "MAPE: 10.091227359709116\n",
      "Test Month: 2021-04-01 00:00:00\n",
      "RMSE: 0.13032938500583754\n",
      "MAPE: 10.074994167965231\n",
      "Test Month: 2021-05-01 00:00:00\n",
      "RMSE: 0.13021996677587697\n",
      "MAPE: 10.076928545287014\n",
      "Test Month: 2021-06-01 00:00:00\n",
      "RMSE: 0.13078854964595454\n",
      "MAPE: 10.123421004772098\n",
      "Test Month: 2021-07-01 00:00:00\n",
      "RMSE: 0.13147561214568523\n",
      "MAPE: 10.200270660809334\n",
      "Test Month: 2021-08-01 00:00:00\n",
      "RMSE: 0.13234714738645867\n",
      "MAPE: 10.30655795625893\n",
      "Test Month: 2021-09-01 00:00:00\n",
      "RMSE: 0.13301101929662873\n",
      "MAPE: 10.393480102972381\n",
      "Test Month: 2021-10-01 00:00:00\n",
      "RMSE: 0.1338073044665467\n",
      "MAPE: 10.489570953061802\n",
      "Test Month: 2021-11-01 00:00:00\n",
      "RMSE: 0.13428043234723175\n",
      "MAPE: 10.57352118226021\n",
      "Test Month: 2021-12-01 00:00:00\n",
      "RMSE: 0.13518980273746897\n",
      "MAPE: 10.697587123814353\n",
      "Test Month: 2022-01-01 00:00:00\n",
      "RMSE: 0.13602111438001316\n",
      "MAPE: 10.802269156284423\n",
      "Test Month: 2022-02-01 00:00:00\n",
      "RMSE: 0.1358645385443698\n",
      "MAPE: 10.782992837126956\n",
      "Test Month: 2022-03-01 00:00:00\n",
      "RMSE: 0.1356958352281901\n",
      "MAPE: 10.759892593791056\n",
      "Test Month: 2022-04-01 00:00:00\n",
      "RMSE: 0.13565264317049844\n",
      "MAPE: 10.732397120439215\n",
      "Test Month: 2022-05-01 00:00:00\n",
      "RMSE: 0.13524047297927758\n",
      "MAPE: 10.699170401561316\n",
      "Test Month: 2022-06-01 00:00:00\n",
      "RMSE: 0.13489316971809276\n",
      "MAPE: 10.659991746605769\n",
      "Test Month: 2022-07-01 00:00:00\n",
      "RMSE: 0.13471092512128385\n",
      "MAPE: 10.634771633923744\n",
      "Test Month: 2022-08-01 00:00:00\n",
      "RMSE: 0.13435765146512196\n",
      "MAPE: 10.594053508897614\n",
      "Test Month: 2022-09-01 00:00:00\n",
      "RMSE: 0.13396137941914968\n",
      "MAPE: 10.553317159139262\n",
      "Test Month: 2022-10-01 00:00:00\n",
      "RMSE: 0.13375365739934011\n",
      "MAPE: 10.530782364073572\n",
      "Test Month: 2022-11-01 00:00:00\n",
      "RMSE: 0.13355389684146496\n",
      "MAPE: 10.498682057870425\n",
      "Test Month: 2022-12-01 00:00:00\n",
      "RMSE: 0.13326944698968557\n",
      "MAPE: 10.457214628820493\n",
      "Test Month: 2023-01-01 00:00:00\n",
      "RMSE: 0.13338406443962822\n",
      "MAPE: 10.439815165111535\n",
      "Test Month: 2023-02-01 00:00:00\n",
      "RMSE: 0.13333095584773827\n",
      "MAPE: 10.425366577390202\n",
      "Test Month: 2023-03-01 00:00:00\n",
      "RMSE: 0.13311051836205395\n",
      "MAPE: 10.404860922021584\n",
      "Test Month: 2023-04-01 00:00:00\n",
      "RMSE: 0.13302057837651587\n",
      "MAPE: 10.377283531290239\n",
      "Test Month: 2023-05-01 00:00:00\n",
      "RMSE: 0.1327591062916204\n",
      "MAPE: 10.340147130485304\n",
      "Test Month: 2023-06-01 00:00:00\n",
      "RMSE: 0.13253017479633372\n",
      "MAPE: 10.305083860434047\n",
      "Test Month: 2023-07-01 00:00:00\n",
      "RMSE: 0.1322824361550246\n",
      "MAPE: 10.273643290178372\n",
      "Test Month: 2023-08-01 00:00:00\n",
      "RMSE: 0.1319701545585538\n",
      "MAPE: 10.235345203481726\n",
      "Test Month: 2023-09-01 00:00:00\n",
      "RMSE: 0.13155608090473261\n",
      "MAPE: 10.1898747610087\n",
      "Test Month: 2023-10-01 00:00:00\n",
      "RMSE: 0.13110051781640034\n",
      "MAPE: 10.14902132800557\n",
      "Test Month: 2023-11-01 00:00:00\n",
      "RMSE: 0.13087359361418557\n",
      "MAPE: 10.125518835930054\n",
      "Test Month: 2023-12-01 00:00:00\n",
      "RMSE: 0.1305647422974968\n",
      "MAPE: 10.097063100731921\n",
      "Test Month: 2024-01-01 00:00:00\n",
      "RMSE: 0.13035612144601408\n",
      "MAPE: 10.08049929782739\n",
      "Test Month: 2024-02-01 00:00:00\n",
      "RMSE: 0.13015602056760212\n",
      "MAPE: 10.064194068814663\n",
      "Test Month: 2024-03-01 00:00:00\n",
      "RMSE: 0.13000981303430834\n",
      "MAPE: 10.044406562439184\n",
      "Test Month: 2024-04-01 00:00:00\n",
      "RMSE: 0.12996934500906207\n",
      "MAPE: 10.02967362642446\n",
      "Test Month: 2024-05-01 00:00:00\n",
      "RMSE: 0.12978432792745379\n",
      "MAPE: 10.01848733672711\n",
      "Test Month: 2024-06-01 00:00:00\n",
      "RMSE: 0.12974291791945355\n",
      "MAPE: 10.016632874033421\n",
      "Test Month: 2024-07-01 00:00:00\n",
      "RMSE: 0.12967612756798583\n",
      "MAPE: 10.020976345103156\n",
      "Test Month: 2024-08-01 00:00:00\n",
      "RMSE: 0.12959760722655359\n",
      "MAPE: 10.023323578542733\n",
      "Test Month: 2024-09-01 00:00:00\n",
      "RMSE: 0.12947570422821025\n",
      "MAPE: 10.022729696836238\n",
      "Final RMSE: 0.12947570422821025\n",
      "Final MAPE: 10.022729696836238\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# # Load data\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "# df[\"date\"] = pd.to_datetime(df[\"year\"].astype(str) + \"-\" + df[\"month\"].astype(str))\n",
    "# df = df.sort_values(\"date\").drop(columns=[\"year\", \"month\"])\n",
    "\n",
    "# # Features and target\n",
    "# features = [col for col in df.columns if col not in [\"target\", \"date\"]]\n",
    "# target = \"target\"\n",
    "df= combined_df\n",
    "# Initialize scaler (StandardScaler for normal distribution, MinMaxScaler for range scaling)\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Initialize model\n",
    "params = {'objective': 'L2', 'n_estimators': 1000, 'learning_rate': 0.05, \n",
    "          'num_leaves': 1000, 'min_data_in_leaves': 10, 'feature_fraction': 0.7, 'max_depth': 75,\n",
    "          'lambda_l2':10e-5, 'path_smooth': 10e-5, 'n_jobs': -1}\n",
    "model = LGBMRegressor(**params, verbose=-1)\n",
    "\n",
    "# Define rolling window parameters\n",
    "min_date = df[\"DATE\"].min()\n",
    "max_date = df[\"DATE\"].max()\n",
    "start_train = min_date\n",
    "test_month = start_train + pd.DateOffset(months=60)\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "while test_month <= max_date:\n",
    "    # Select training and testing data\n",
    "    train_idx = df[\"DATE\"] < test_month\n",
    "    test_idx = df[\"DATE\"] == test_month\n",
    "    print(\"Test Month:\", test_month)\n",
    "    X_train, y_train = df.loc[train_idx, features], df.loc[train_idx, target]\n",
    "    X_test, y_test = df.loc[test_idx, features], df.loc[test_idx, target]\n",
    "\n",
    "    if X_train.empty or X_test.empty:\n",
    "        break\n",
    "\n",
    "    # **Online Feature Scaling**\n",
    "    # if start_train == min_date:\n",
    "    #     scaler.fit(X_train)  # Fit scaler only on first window\n",
    "    # else:\n",
    "    #     scaler.partial_fit(X_train)  # Update scaler with new window\n",
    "\n",
    "    # X_train_scaled = scaler.transform(X_train)\n",
    "    # X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # **Online Model Training**\n",
    "    if start_train == min_date:\n",
    "        model.fit(X_train, y_train)  # Train on first batch\n",
    "    else:\n",
    "        model.set_params(n_estimators=model.n_estimators + 20)  # Add new trees\n",
    "        model.fit(X_train, y_train, init_model=model)\n",
    "\n",
    "    # Predictions\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    predictions.extend(preds)\n",
    "    actuals.extend(y_test.values)\n",
    "\n",
    "    rmse = root_mean_squared_error(actuals, predictions)\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    mape = np.mean(np.abs((np.exp(actuals) - np.exp(predictions)) / np.exp(predictions))) * 100\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    # Move window forward\n",
    "    test_month += pd.DateOffset(months=1)\n",
    "\n",
    "# Evaluate model\n",
    "rmse = root_mean_squared_error(actuals, predictions)\n",
    "print(f\"Final RMSE: {rmse}\")\n",
    "mape = np.mean(np.abs((np.exp(actuals) - np.exp(predictions)) / np.exp(predictions))) * 100\n",
    "print(f\"Final MAPE: {mape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
